\chapter{Discussion}
\label{chap:discussion}

This chapter contains an assessment of the results and implementations, talking about some of the trade-offs as evidenced by the results\ref{chap:results}. It will also use this information to comment on what a more complete pipeline might look like. 

There are a couple of things to mention about the effect of resizing the image on registration speed:
\begin{itemize}
    \item The dip in the speedup on \autoref{fig:resizing-speedup} on \(R=0.75\) can be explained as the penalty incurred by adding the extra step of resizing the image.
    \item The speedup is more evident on the Fourier-Mellin Pipeline as it has extra modules that are affected by the frame size: Fourier Transform, and Log-Polar Transform. 
\end{itemize}

It was unexpected for the Fourier-Mellin Pipeline to outperform the \citeauthor{Hurtos2015}'s Pipeline in registration time. However, \autoref{fig:resizing-speedup} seems to suggest that given a small enough resizing ratio, the Fourier-Mellin Pipeline executes much faster. \citeauthor{Hurtos2015}'s claims don't take into account resizing, and in this case, their pipeline clearly outperforms \citeauthor{Reddy1996}'s Fourier-Mellin version.

On pure rotational movement, the \citeauthor{Hurtos2015}'s Pipeline performs so much better than the Fourier-Mellin Pipeline. This could be developed into an application of its own. If the sonar mosaic doesn't have to allow for translations, one could imagine a mode where the \acrshort{rov} rotates about its center and restricts translational movement. This would result in very accurate mosaics of the area around the drone. Another advantage of this approach is that this is closer to one of the cases for homography estimation with no caveats as mentioned in \autoref{sec:mosaicing}: rotation about the camera center. This assures no perturbations from shadows since they would always be in the same place. This allows us to get the best of both approaches.

Mosaicing has the side-effect of improving the resolution of the images. There are a couple of things that seem to affect this. First, parts of the image at a shorter range tend to have higher resolution. This is a side-effect of the Fan Transformation. At higher ranges the beams are farther apart which results in lower resolutions, but as they get closer to the source there is a higher concentration of data in a smaller area. Mosaicing lets us take advantage of both of these areas. Even at low resolution, averaging of the frames results in clearer images as they all contain "a little piece of the puzzle". The higher-resolution part of the image helps improve the resolution of the areas over which it passes as well. 

Although skipping frames could help in achieving real-time performance, mosaicing distant frames like in \autoref{fig:fmtranslationmosaic} could result in evident seams, which is not ideal. Choosing how many frames to skip should be tuned to the speed of the vehicle, and as seen in the results for translations in either axis, should aim to be less than 9 frames in between. The effect seems to be less on pure rotation as in \autoref{fig:pcmosaic}, where the seams are less noticeable. 

One of the main pitfalls of the Fourier-Mellin Pipeline when applied over sonar frames is the sheer number of transformations that are applied over it, and that it relies on working on images that have already undergone a Fan Transformation. This transformation is very lossy since every beam is compressed into a single origin point. A lot of usable data is lost in this overlap. On top of this, the rotation is estimated through too many steps: Fan Transformation $\rightarrow$ Fourier $\rightarrow$ Log-Polar Transform $\rightarrow$ Phase Correlation. It is evident that \citeauthor{Hurtos2015}'s approach is not only faster by performing Phase Correlation directly on the source image but also more accurate for small rotations/translations. 

Another disadvantage of the Fourier-Mellin approach is the Band-pass Filter pre-processing step, which introduces more parameters that must be tuned to achieve good performance. It is also present in the Raw Polar, but only for registering translations. On the Raw Polar Pipeline, tuning the Band-pass Filter has no effect on rotations. From this, it is evident that the Raw Polar Pipeline's approach to use the raw data for registering rotations is more robust than its Fourier-Mellin counterpart. Tuning the Band-pass Filter is a tough task as there is no obvious metric to choose when evaluating these parameters, since we lack the data to determine what the underlying signal in the frame actually is. 

On the other hand, one of the main pitfalls of the \citeauthor{Hurtos2015}'s pipeline is that it can't deal with distant rotations and translations as effectively as \citeauthor{Reddy1996}'s. This is a side-effect of running phase correlation over the raw frame, which is interpreted as a polar representation of the scene. While \citeauthor{Reddy1996}'s decouples rotations from translations by using the Fourier transform of the images, \citeauthor{Hurtos2015}'s applies phase correlation over the raw images. This is a smart optimization assuming very little translation between frames, but this approach will definitely struggle over not-so-closely aligned frames. As evidenced by \autoref{sec:sway-hurtos} and \autoref{sec:surge-hurtos}, the Raw Polar Pipeline is only good at registering surge translations, as it can't deal with pure sway. Rotations aren't decoupled from translations in the polar space, and so it turns out that translations along the sway axis (left and right) inflict the most change on the perceived rotation, affecting the overall registration. 

According to \citeauthor{Hurtos2015}\cite{Hurtos2015}:
\begin{quote}
    \textit{However, when working with the polar images, rotation is not decoupled from translational displacements, and shifts in Cartesian space create distortions in the polar domain. If the translational displacements are relatively small compared to the imageâ€™s size in each direction, the induced distortions in the polar image still allow for the recovery of the rotation by computing the shift in the angular direction.}
\end{quote}

It appears that they do not seem to realize that overall translational displacement is not the only metric to consider, but whether or not this translation is mostly on the surge or sway axis.

Another overlook on their part is the possibility of uneven spacing between beams according to the bearing table. This might currently be introducing some small error into the rotation estimation part of the pipeline. The uneven spacing is not taken into account by the algorithm currently, it only considers the \acrshort{fov}. 


Combining the strengths of both algorithms should be further explored, but given these results, they could be useful for adding global alignment to the process. So far, the described pipelines have focused on pair-wise registration of consecutive frames. According to \citeauthor{Hurtos2015}\cite{Hurtos2015} this open chain will lead to high cumulative error. To address this, \citeauthor{Hurtos2015}\cite{Hurtos2015} and \citeauthor{Das2021}\cite{Das2021} propose adding global alignment which involves attempting registration between non-consecutive frames that might be in the spatial or temporal vicinity of the current one, or using data from other sources, such as GPS, or in our case \acrshort{dvl} positioning. This data is merged with the original transformation chain using pose-based graphs. A pose graph, as proposed by \citeauthor{Kummerle2011}\cite{Kummerle2011} expresses positions as nodes and relative transformations as edges. As more edges are added, for example as the result of attempting global alignment the more information is available to try to minimize the error along the longer chains. A new combined pipeline might use \citeauthor{Hurtos2015}'s approach for incoming consecutive frames, but use the proposed adaptations to \citeauthor{Reddy1996}'s Fourier-Mellin Pipeline for global alignment against frames suspected to be in the vicinity.

On a separate note, it is interesting to see how the estimations seem to move in discrete steps, probably because increments in translation/rotation estimation are directly linked to pixel values, which are discrete themselves. In addition, down-sampling the image must decrease the number of discrete steps as it reduces the number of pixels. 

It is hard to evaluate the performance of the frames on real data, in particular, because it's hard to determine what the reference value should be. Rotations are easier because the pilot has more input about the heading and can control the drone to stay within certain ranges. Dimensions on features visible in the mosaics from \autoref{fig:sonar-mosaic} seem to be preserved even when the registration chain adds up to a bigger rotation than what was actually performed.